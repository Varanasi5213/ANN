{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP(Bayes).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2hjDGpxtYzl"
      },
      "source": [
        "# Bayes Classification For Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWYq2Py5tYfR"
      },
      "source": [
        "### Using 5 Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y95VsLqPftTy"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"Corona_NLP_train.csv\", encoding='latin-1')\n",
        "T= pd.read_csv(\"Corona_NLP_test.csv\")\n",
        "df.Sentiment.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTc9p61IqKUs"
      },
      "source": [
        "import re\n",
        "def remove_urls(text): # to remove HTTP links\n",
        "    return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
        "df['OriginalTweet']=df['OriginalTweet'].apply(lambda x:remove_urls(x))\n",
        "T['OriginalTweet']=T['OriginalTweet'].apply(lambda x:remove_urls(x))\n",
        "df1['OriginalTweet'].str.replace('http.*.com', '',regex = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_zjFeeMq4W0"
      },
      "source": [
        "def remove_urls(text): # to remove HTML tags\n",
        "    return re.sub(r'<.*?>', '', text)\n",
        "df['OriginalTweet']=df['OriginalTweet'].apply(lambda x:remove_urls(x))\n",
        "T['OriginalTweet']=T['OriginalTweet'].apply(lambda x:remove_urls(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njxeg5B5knxi"
      },
      "source": [
        "# Converting Clases\n",
        "df['Sentiment']=df.Sentiment.replace('Neutral',0)\n",
        "T['Sentiment']=T.Sentiment.replace('Neutral',0)\n",
        "df['Sentiment']=df.Sentiment.replace('Positive',1)\n",
        "T['Sentiment']=T.Sentiment.replace('Positive',1)\n",
        "df['Sentiment']=df.Sentiment.replace('Negative',-1)\n",
        "T['Sentiment']=T.Sentiment.replace('Negative',-1)\n",
        "df['Sentiment']=df.Sentiment.replace('Extremely Negative',-2)\n",
        "T['Sentiment']=T.Sentiment.replace('Extremely Negative',-2)\n",
        "df['Sentiment']=df.Sentiment.replace('Extremely Positive',2)\n",
        "T['Sentiment']=T.Sentiment.replace('Extremely Positive',2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdWvi9Oeiop5"
      },
      "source": [
        "reviews = df[[\"OriginalTweet\",\"Sentiment\"]].values\n",
        "test = T[[\"OriginalTweet\",\"Sentiment\"]].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5k-XKq3fg85"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "# Generate counts from text using a vectorizer.  \n",
        "# This performs our step of computing word counts.\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
        "test_features = vectorizer.transform([r[0] for r in test])\n",
        "\n",
        "# Fit a naive bayes model to the training data.\n",
        "# This will train the model using the word counts we computer, \n",
        "#and the existing classifications in the training set.\n",
        "nb = MultinomialNB()\n",
        "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
        "\n",
        "# predict classifications for our test features.\n",
        "predictions = nb.predict(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6VYu3VdjSAD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5272936f-8152-455c-bf46-3770b74aaa47"
      },
      "source": [
        "actual =T[\"Sentiment\"].values\n",
        "# Compute the error.\n",
        "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
        "print(\"Multinomial naive bayes AUC: {0}\".format(metrics.auc(fpr, tpr)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial naive bayes AUC: 0.6225657867689026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMkdstx8oJgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7b9289c6-8262-4325-ec5f-a15c4effaa65"
      },
      "source": [
        "# confusion matrix to understand where is the \n",
        "# classifier wrongly clasifying\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c=confusion_matrix(actual, predictions, labels=[2, 1, 0,-1,-2])\n",
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[174, 366,   5,  49,   5],\n",
              "       [ 54, 624,  27, 214,  28],\n",
              "       [ 14, 275, 138, 179,  13],\n",
              "       [ 11, 361,  50, 559,  60],\n",
              "       [  1,  80,   6, 340, 165]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27wEd2u4tw3f"
      },
      "source": [
        "there is lot ofconfusion between **\"Extremely Positive\"** and **\"Positive\"**\n",
        "& **\"Extremely Negative\"** and **\"Negative\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtibyfb-pI7C"
      },
      "source": [
        "sum=0\n",
        "for i in range(5):\n",
        "  for j in range(5):\n",
        "    if i != j:\n",
        "      sum = sum + c[i][j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzefr_rWr37_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bed6c7b-b12a-47fb-cad4-955c439f169b"
      },
      "source": [
        "sum/len(actual) # fraction of wrongly classified rows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5629278567667193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gGc-ZauQlh"
      },
      "source": [
        "So Combining these classes increases the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tov2EOztRXz"
      },
      "source": [
        "### Using 3 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0SQvWM_sc5d"
      },
      "source": [
        "df = pd.read_csv(\"Corona_NLP_train.csv\", encoding='latin-1')\n",
        "T= pd.read_csv(\"Corona_NLP_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Uit2hqsc8o"
      },
      "source": [
        "import re\n",
        "def remove_urls(text):\n",
        "    return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
        "df['OriginalTweet']=df['OriginalTweet'].apply(lambda x:remove_urls(x))\n",
        "T['OriginalTweet']=T['OriginalTweet'].apply(lambda x:remove_urls(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfk4DfIKsc2c"
      },
      "source": [
        "def remove_urls(text):\n",
        "    return re.sub(r'<.*?>', '', text)\n",
        "df['OriginalTweet']=df['OriginalTweet'].apply(lambda x:remove_urls(x))\n",
        "T['OriginalTweet']=T['OriginalTweet'].apply(lambda x:remove_urls(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnM2rzAEslXb"
      },
      "source": [
        "# Converting classes\n",
        "df['Sentiment']=df.Sentiment.replace('Neutral',0)\n",
        "T['Sentiment']=T.Sentiment.replace('Neutral',0)\n",
        "df['Sentiment']=df.Sentiment.replace('Positive',1)\n",
        "T['Sentiment']=T.Sentiment.replace('Positive',1)\n",
        "df['Sentiment']=df.Sentiment.replace('Negative',-1)\n",
        "T['Sentiment']=T.Sentiment.replace('Negative',-1)\n",
        "df['Sentiment']=df.Sentiment.replace('Extremely Negative',-1)\n",
        "T['Sentiment']=T.Sentiment.replace('Extremely Negative',-1)\n",
        "df['Sentiment']=df.Sentiment.replace('Extremely Positive',1)\n",
        "T['Sentiment']=T.Sentiment.replace('Extremely Positive',1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF9f8GBhucA6"
      },
      "source": [
        "here there are only 3 classes 1,0,-1 made by combining **'Extremely Positive','Positive'** and **'Extremely Negative','Negative'**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITsYrUvPspRv"
      },
      "source": [
        "reviews = df[[\"OriginalTweet\",\"Sentiment\"]].values\n",
        "test = T[[\"OriginalTweet\",\"Sentiment\"]].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSNS6XK9s0Zq"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "# Generate counts from text using a vectorizer.  There are other vectorizers available, and lots of options you can set.\n",
        "# This performs our step of computing word counts.\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
        "test_features = vectorizer.transform([r[0] for r in test])\n",
        "\n",
        "# Fit a naive bayes model to the training data.\n",
        "# This will train the model using the word counts we computer, and the existing classifications in the training set.\n",
        "nb = MultinomialNB()\n",
        "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
        "\n",
        "# Now we can use the model to predict classifications for our test features.\n",
        "predictions = nb.predict(test_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7LY3QKzs3l0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e370cd17-4ea0-4121-813d-371adc89321f"
      },
      "source": [
        "actual =T[\"Sentiment\"].values\n",
        "# Compute the error.  It is slightly different from our model because the internals of this process work differently from our implementation.\n",
        "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
        "print(\"Multinomial naive bayes AUC: {0}\".format(metrics.auc(fpr, tpr)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial naive bayes AUC: 0.7385592567997629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzbRRuius4_k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9df75b7c-85a8-4003-ba84-85b64eb7a361"
      },
      "source": [
        "# confusion matrix to understand where is the \n",
        "# classifier wrongly clasifying\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c=confusion_matrix(actual, predictions, labels=[1, 0,-1])\n",
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1213,   16,  317],\n",
              "       [ 307,   88,  224],\n",
              "       [ 375,   36, 1222]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c24TU6n3wEyI"
      },
      "source": [
        "True Positives have increased\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwhHSgQ9s-75"
      },
      "source": [
        "sum=0\n",
        "for i in range(3):\n",
        "  for j in range(3):\n",
        "    if i != j:\n",
        "      sum = sum + c[i][j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FurYuJw5tDvz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf62a773-1a20-4379-96c7-aa963817f9a3"
      },
      "source": [
        "sum/len(actual)# fraction of wrongly classified rows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33570300157977884"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhU56ApsxGSd"
      },
      "source": [
        "This has dicreased from previous version"
      ]
    }
  ]
}